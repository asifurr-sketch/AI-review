# Metadata

**Category:** - Coding

**GitHub URL:** - https://github.com/NOI-gen/crest_of_the_lantern_wave_strict_peak_edition

**Topic:** - Competitive Programming

**Subtopic:** - ["Basic Data Structures", "Arrays and Lists", "Sorting Algorithms", "Searching Algorithms", "Dynamic Programming", "Trees and Tries", "Algorithm Complexity and Big O Notation"]

**Difficulty:** - Hard

**Languages:** - C++

**Number of Approaches:** $4$: $O(2^m) \rightarrow O(m^2) \rightarrow O(m\log m) \rightarrow O\big((n+m)\log m\big)$

**Number of Chains:** $11$

---

**[User]**

*Demark the start of the User's activity*

**[PROMPT]**

# Crest of the Lantern Wave (Strict Peak Edition)

Time Limit: **1 seconds**

Memory Limit: **34 MB**

Every year, a night parade walks along a straight avenue marked with posts $1$ through $m$. Each of the $n$ floats casts a spell of light over a contiguous stretch of posts $[l_i, r_i]$. At a post $x$, the brightness is the number of spells that cover $x$.

You want to plan a "wave" of cheers by choosing some posts in increasing order so that the observed brightness along those posts first never decreases and then, after a single peak position, strictly decreases. Among all such cheering waves, find:
- $K$: the maximum possible number of posts in such a wave.
- $W$: how many distinct waves achieve this maximum length (modulo $1000000007$).

Formally, let $b(x)$ be the brightness at post $x$. A wave is a sequence $x_1 < x_2 < \dots < x_k$ such that there exists a pivot $p$ with $1 \le p \le k$ where:
- $b(x_1) \le b(x_2) \le \dots \le b(x_p)$, and
- $b(x_p) > b(x_{p+1}) > \dots > b(x_k)$.

The pivot can be at the first or the last post; the strictly decreasing part may be empty.

It is guaranteed that no post is lit by all $n$ spells.

**Input Format:-**
- The first line contains two integers $n$ and $m$.
- Each of the next $n$ lines contains two integers $l_i$ and $r_i$ describing the interval $[l_i, r_i]$ illuminated by the $i$-th float.

**Output Format:-**
Print two integers $K$ and $W$. Here $K$ is the maximum length of a valid wave, and $W$ is the number of distinct waves that achieve this length, taken modulo $1000000007$.

**Constraints:-**
- $1 \le n, m \le 100000$
- $1 \le l_i \le r_i \le m$
- No post is covered by all $n$ intervals

**Examples:-**
 - **Input:**
```
3 6
1 3
1 3
4 6
```

 - **Output:**
```
4 3
```
 - **Explanation:**

    **Example 1.1 - Brightness calculation:** intervals $[1,3],[1,3],[4,6]$ ⇒ $b=[2,2,2,1,1,1]$.

    **Example 1.2 - Optimal wave construction:** take all three 2's (nondecreasing), then **exactly one** 1 (must strictly decrease; cannot take two 1's).  
    - Length $K=3+1=4$.  
    - Choices for the final 1: posts 4, 5, or 6 ⇒ $W=3$.

 - **Input:**
```
6 8
1 5
2 5
3 5
6 8
6 7
8 8
```

 - **Output:**
```
6 3
```
 - **Explanation:**

    **Example 2.1 - Brightness calculation:** intervals $[1,5],[2,5],[3,5],[6,8],[6,7],[8,8]$ ⇒ $b=[1,2,3,3,3,2,2,2]$.

    **Example 2.2 - Optimal wave construction:** take posts 1–5 with values $1,2,3,3,3$ (nondecreasing), then **exactly one** 2 from posts 6–8 (strictly decreasing forbids a second 2).  
    - Length $K=5+1=6$.  
    - Choices for the final 2: posts 6, 7, or 8 ⇒ $W=3$.

---

**[Assistant]**

Demark the start of the Assistant's activity

---

**[CHAIN_01]**

Understanding the Problem Requirements

**THOUGHT_01_01**

The problem requires finding the maximum length wave and counting all such maximum-length waves. A wave has two parts: a non-decreasing prefix ending at a pivot, and a strictly decreasing suffix starting at the pivot. The key insight is that for any pivot position $postIndex$, the maximum wave length through $postIndex$ is $lndsLength[postIndex] + ldsLength[postIndex] - 1$, where $lndsLength[postIndex]$ is the longest non-decreasing subsequence ending at $postIndex$ and $ldsLength[postIndex]$ is the longest strictly decreasing subsequence starting at $postIndex$.


**THOUGHT_01_02**

The constraints are significant: up to $10^5$ intervals and $10^5$ posts, with brightness values in $[0, numIntervals-1]$. This suggests we need an efficient algorithm, likely $O((numIntervals + numPosts) \log numPosts)$ or better. The modulo requirement of $1000000007$ indicates we need to handle large counts carefully.


---

**[CHAIN_02]**

Analyzing Test Cases and Edge Cases

**THOUGHT_02_01**

Consider a simple case with $numIntervals = 2$, $numPosts = 5$, and intervals $[(1,3), (2,4)]$. This creates brightness array $[0, 1, 2, 2, 1, 0]$. The optimal wave has length $3$ with $2$ ways, using posts $2, 3, 4$ or $2, 3, 5$ as pivots.


**THOUGHT_02_02**

Edge cases include: single post ($K=1, W=1$), all posts with equal brightness ($K=numPosts, W=1$), strictly increasing brightness ($K=numPosts, W=1$ with pivot at end), and strictly decreasing brightness ($K=numPosts, W=1$ with pivot at start).


**THOUGHT_02_03**

Critical test case: brightness $[1, 3, 3, 3, 2]$ where multiple posts have the same maximum brightness. This tests our handling of equal values in the non-decreasing part and ensures we count all valid pivot positions correctly.


---

**[CHAIN_03]**

Exploring Brute Force Approach

**THOUGHT_03_01**

The naive approach would enumerate all possible increasing subsequences of posts and check if they form a valid wave. However, this requires checking $O(2^{numPosts})$ subsets, which is computationally infeasible for $numPosts = 10^5$.



**THOUGHT_03_02**

A slightly better approach would fix each possible pivot position and compute the longest non-decreasing subsequence ending at that position and the longest strictly decreasing subsequence starting at that position. However, doing this with a simple $O(numPosts^2)$ DP for each pivot would result in $O(numPosts^3)$ total complexity, still too slow.


**THOUGHT_03_03**

The brute force approach reveals the core challenge: we need to compute both lengths and counts for subsequences ending/starting at each position, but doing this naively is too expensive. This motivates the need for a more sophisticated data structure approach.


---

**[CHAIN_04]**

Developing the Optimal Solution Strategy

**THOUGHT_04_01**

The key insight is to use coordinate compression to map brightness values to a compact range, then use Fenwick trees to efficiently query and update the best subsequence information. For the left-to-right pass (non-decreasing), we query all positions with brightness $\leq brightness[postIndex]$. For the right-to-left pass (strictly decreasing), we query positions with brightness $< brightness[postIndex]$.


**THOUGHT_04_02**

We store in each Fenwick tree node a pair $(maxLength, numWays)$ representing the best subsequence length and count of ways to achieve it. The merge operation chooses the larger length; if lengths are equal, it sums the ways modulo $1000000007$.


**THOUGHT_04_03**

Corner cases to handle: when $r = m$, skip the decrement at $r + 1$; make sure the difference array is sized at least $m + 1$ (or $m + 2$) to safely write $d[r + 1]$; ensure we use 1-based indexing consistently to match the problem statement.


**THOUGHT_04_03**

The algorithm proceeds in four steps: (1) Build brightness array using difference array technique in $O(numIntervals + numPosts)$ time, (2) Compress brightness values to ranks in $O(numPosts \log numPosts)$ time, (3) Compute left and right DP using Fenwick trees in $O(numPosts \log numPosts)$ time each, (4) Combine results to find maximum wave length and count in $O(numPosts)$ time.


---

**[CHAIN_05]**

Addressing Implementation Challenges

**THOUGHT_05_01**

The difference array technique is crucial for efficient brightness construction. For each interval $[left, right]$, we increment $differenceArray[left]$ and decrement $differenceArray[right+1]$, then compute prefix sums to get the final brightness values.


**THOUGHT_05_02**

Coordinate compression must handle duplicate brightness values correctly. We sort all unique brightness values and map each value to its rank in the sorted array. This ensures the Fenwick tree operates on a compact range $[1, numRanks]$ where $numRanks \leq numPosts$.


**THOUGHT_05_03**

The merge operation in the Fenwick tree must be associative and handle ties correctly. When two states have equal maximum lengths, we sum their ways. When starting a new subsequence (no valid predecessor), we set $numWays = 1$.


---

**[CHAIN_06]**

Validating Correctness and Efficiency

**THOUGHT_06_01**

The strictness constraint on the right side (strictly decreasing) is crucial for correctness. It ensures each maximum wave is counted exactly once at its unique pivot position, preventing double counting that would occur if we allowed non-increasing sequences.


**THOUGHT_06_02**

The overall complexity is $O((numIntervals + numPosts) \log numPosts)$ time and $O(numPosts)$ space, which comfortably handles the constraints. The difference array construction is $O(numIntervals + numPosts)$, coordinate compression is $O(numPosts \log numPosts)$, and each Fenwick pass is $O(numPosts \log numPosts)$.


**THOUGHT_06_03**

Modular arithmetic must be handled carefully throughout. All additions of ways must be done modulo $1000000007$, and the product $lndsCount[postIndex] \cdot ldsCount[postIndex]$ can overflow 32-bit integers, so we compute it in 64-bit arithmetic before reducing modulo $1000000007$.


---

**[RESPONSE]**

# Crest of the Lantern Wave - Optimal Solution Analysis

## Problem Understanding

We are given $numIntervals$ light intervals on posts labeled $1$ to $numPosts$. Each interval $[left, right]$ illuminates every post in that range. The brightness at post $postIndex$, denoted $brightness[postIndex]$, is the number of intervals covering $postIndex$.

We need to select an increasing sequence of posts $x_1 < x_2 < \dots < x_k$ that forms a "wave":
- The brightnesses are non-decreasing up to a pivot, and then strictly decreasing after the pivot.
- The pivot can be at the first or last post; the strictly decreasing part may be empty.

We must compute:
- $K$: the maximum possible length $k$ of such a wave.
- $W$: the number of distinct maximum-length waves, modulo $1000000007$.

### Key Observations

- Define $lndsLength[postIndex]$ as the length of the longest non-decreasing subsequence ending at position $postIndex$, and $ldsLength[postIndex]$ as the length of the longest strictly decreasing subsequence starting at position $postIndex$.
- For a pivot at $postIndex$, the best possible wave length through $postIndex$ is $lndsLength[postIndex] + ldsLength[postIndex] - 1$.
- Let $lndsCount[postIndex]$ be the number of optimal left subsequences (achieving $lndsLength[postIndex]$) ending at $postIndex$, and $ldsCount[postIndex]$ the number of optimal right subsequences (achieving $ldsLength[postIndex]$) starting at $postIndex$.
- The answers are:
  - $K = \max_{postIndex} \{lndsLength[postIndex] + ldsLength[postIndex] - 1\}$.
  - $W = \sum_{postIndex: lndsLength[postIndex] + ldsLength[postIndex] - 1 = K} \big(lndsCount[postIndex] \cdot ldsCount[postIndex]\big) \bmod 1000000007$.
- The strictness on the right guarantees a unique pivot for each wave, avoiding double counting.

## Optimal Approach

We proceed in four steps:

### 1) Build Brightness via Difference Array
- Maintain an auxiliary array $differenceArray[1 \dots numPosts+1]$.
- For each $[left, right]$, do $differenceArray[left] += 1$ and if $right+1 \le numPosts$ then $differenceArray[right+1] -= 1$.
- Prefix sum over $differenceArray$ to obtain $brightness[1], \dots, brightness[numPosts]$.
- **Complexity**: $O(numIntervals + numPosts)$.

### 2) Coordinate Compression
- Compress brightness values to ranks $1 \dots numRanks$ where $numRanks \le numPosts$, to index in a Fenwick tree.
- **Complexity**: $O(numPosts \log numPosts)$.

### 3) Two Fenwick Tree Passes to Compute Lengths and Counts
- Store in each Fenwick node a pair $(maxLength, numWays)$, merged by choosing the larger $maxLength$; on ties, sum $numWays$ modulo $1000000007$.
- **Left-to-right (non-decreasing)**:
  - For rank $rank$ of $brightness[postIndex]$, query prefix $[1, rank]$ to get best $(\ell, c)$.
  - Set $lndsLength[postIndex] = \ell + 1$, $lndsCount[postIndex] = 1$ if $\ell = 0$ else $c$.
  - Update index $rank$ with $(lndsLength[postIndex], lndsCount[postIndex])$.
- **Right-to-left (strictly decreasing)**:
  - For rank $rank$ of $brightness[postIndex]$, query prefix $[1, rank - 1]$ to enforce strictness and get $(\ell, c)$.
  - Set $ldsLength[postIndex] = \ell + 1$, $ldsCount[postIndex] = 1$ if $\ell = 0$ else $c$.
  - Update index $rank$ with $(ldsLength[postIndex], ldsCount[postIndex])$.
- **Complexity per pass**: $O(numPosts \log numPosts)$.

### 4) Combine Results
- Compute $K = \max_{postIndex} \{lndsLength[postIndex] + ldsLength[postIndex] - 1\}$.
- Compute $W = \sum_{postIndex: lndsLength[postIndex] + ldsLength[postIndex] - 1 = K} lndsCount[postIndex] \cdot ldsCount[postIndex] \bmod 1000000007$.
- **Complexity**: $O(numPosts)$.

**Overall complexity**: $O((numIntervals + numPosts) \log numPosts)$ time and $O(numPosts)$ space.

## Full Code

```cpp
#include <iostream>
#include <vector>
#include <algorithm>
#include <cstdint>

/*
 * Prime modulus for counting distinct waves.
 * 1e9+7 is standard in programming contests due to being prime and fitting in 32-bit signed range.
 */
static const int MODULUS = 1000000007;

/*
 * DP state storing the best subsequence length and the number of ways to achieve it.
 */
struct DpState {
    int maxLength;    // Best subsequence length
    int numWays;      // Number of ways to achieve this length (mod MODULUS)
};

/*
 * Merge two DP states by keeping the larger length and summing ways on ties.
 * This is the standard combine rule when tracking (best length, count of best) over prefixes.
 */
DpState combineStates(const DpState& firstState, const DpState& secondState) {
    if (firstState.maxLength > secondState.maxLength) return firstState;
    if (secondState.maxLength > firstState.maxLength) return secondState;
    
    int combinedWays = firstState.numWays + secondState.numWays;
    if (combinedWays >= MODULUS) combinedWays -= MODULUS;
    return DpState{firstState.maxLength, combinedWays};
}

/*
 * Fenwick tree (Binary Indexed Tree) that maintains (max length, count of ways) over prefixes.
 *
 * The tree supports:
 * - update(rank, state): state = combine(state, tree[rank]) up the tree
 * - query(rank): returns combined state over [1..rank]
 *
 * We use it twice:
 * 1) Left-to-right for longest nondecreasing subsequence (LNDS) ending at each index.
 * 2) Right-to-left for longest strictly decreasing subsequence (LDS) starting at each index.
 *
 * Note: This is a specialized structure; while Fenwick is often used for sums,
 * using "max + tie-count" as the monoid is valid because combineStates is associative
 * and we only ever extend in one direction of indices.
 */
class FenwickMaxCount {
public:
    /*
     * Construct a Fenwick tree over indices [1..numRanks].
     *
     * @param numRanks Number of ranks/indices in the compressed coordinate space.
     */
    explicit FenwickMaxCount(int numRanks)
        : numRanks_(numRanks), tree_(numRanks + 1, DpState{0, 0}) {}

    /*
     * Update a frequency/rank index with a new state via combine.
     *
     * @param rankIndex 1-based index in [1..numRanks_].
     * @param newState The DpState to merge into the Fenwick structure.
     */
    void update(int rankIndex, const DpState& newState) {
        for (; rankIndex <= numRanks_; rankIndex += rankIndex & -rankIndex) {
            tree_[rankIndex] = combineStates(tree_[rankIndex], newState);
        }
    }

    /*
     * Query the combined state over prefix [1..rankIndex].
     *
     * @param rankIndex 1-based right endpoint of the query.
     * @return Combined DpState for the prefix.
     */
    DpState query(int rankIndex) const {
        DpState result{0, 0};
        for (; rankIndex > 0; rankIndex -= rankIndex & -rankIndex) {
            result = combineStates(result, tree_[rankIndex]);
        }
        return result;
    }

private:
    int numRanks_;
    std::vector<DpState> tree_;
};

/*
 * Build the brightness array brightness[1..numPosts] from the list of intervals using a difference array.
 *
 * @param numPosts The number of posts.
 * @param intervals Vector of closed intervals [left, right] (1-based) representing spells.
 * @return Vector<int> of size numPosts+1 where brightness[postIndex] is the brightness at post postIndex for postIndex in [1..numPosts].
 */
std::vector<int> buildBrightness(int numPosts, const std::vector<std::pair<int,int>>& intervals) {
    std::vector<int> differenceArray(numPosts + 2, 0);  // +2 safe for right+1
    for (const auto& interval : intervals) {
        int left = interval.first;
        int right = interval.second;
        differenceArray[left] += 1;
        if (right + 1 <= numPosts) differenceArray[right + 1] -= 1;
    }
    std::vector<int> brightness(numPosts + 1, 0); // 1..numPosts used
    int runningSum = 0;
    for (int postIndex = 1; postIndex <= numPosts; ++postIndex) {
        runningSum += differenceArray[postIndex];
        brightness[postIndex] = runningSum;
    }
    return brightness;
}

/*
 * Produce a sorted unique list of values for coordinate compression.
 *
 * @param values Input values to compress.
 * @return A sorted vector with unique values (the compression dictionary).
 */
std::vector<int> makeCompressionDictionary(const std::vector<int>& values) {
    std::vector<int> compressionDict(values.begin() + 1, values.end()); // skip index 0 (unused)
    std::sort(compressionDict.begin(), compressionDict.end());
    compressionDict.erase(std::unique(compressionDict.begin(), compressionDict.end()), compressionDict.end());
    return compressionDict;
}

/*
 * Get the 1-based rank of a value in the compression dictionary.
 *
 * @param compressionDict Sorted unique values (compression dictionary).
 * @param targetValue Value to rank.
 * @return 1-based rank of targetValue.
 */
int getRank(const std::vector<int>& compressionDict, int targetValue) {
    return static_cast<int>(std::lower_bound(compressionDict.begin(), compressionDict.end(), targetValue) - compressionDict.begin()) + 1;
}

/*
 * Compute, for each index postIndex, the length and count of the Longest Nondecreasing Subsequence (LNDS) ending at postIndex.
 *
 * The DP recurrence for index postIndex with brightness rank rank:
 *   bestState = fenwick.query(rank)  // consider all previous positions with value <= brightness[postIndex]
 *   lndsLength[postIndex]  = bestState.maxLength + 1
 *   lndsCount[postIndex]  = (bestState.maxLength == 0 ? 1 : bestState.numWays)  // starting fresh vs extending
 *
 * @param brightness Brightness array brightness[1..numPosts].
 * @param compressionDict Compression dictionary for brightness.
 * @param lndsLength Output vector: lndsLength[postIndex] = LNDS length ending at postIndex.
 * @param lndsCount Output vector: lndsCount[postIndex] = #ways for that LNDS at postIndex (mod MODULUS).
 */
void computeLeftNondecreasingDp(const std::vector<int>& brightness,
                                const std::vector<int>& compressionDict,
                                std::vector<int>& lndsLength,
                                std::vector<int>& lndsCount) {
    int numPosts = static_cast<int>(brightness.size()) - 1;
    lndsLength.assign(numPosts + 1, 0);
    lndsCount.assign(numPosts + 1, 0);

    FenwickMaxCount fenwick(static_cast<int>(compressionDict.size()));

    for (int postIndex = 1; postIndex <= numPosts; ++postIndex) {
        int rank = getRank(compressionDict, brightness[postIndex]);
        DpState bestState = fenwick.query(rank);  // allow equal => nondecreasing
        int currentLength = bestState.maxLength + 1;
        int currentWays = (bestState.maxLength == 0 ? 1 : bestState.numWays);
        lndsLength[postIndex] = currentLength;
        lndsCount[postIndex] = currentWays;
        fenwick.update(rank, DpState{currentLength, currentWays});
    }
}

/*
 * Compute, for each index postIndex, the length and count of the Longest Strictly Decreasing Subsequence (LDS) starting at postIndex.
 *
 * Scanning right-to-left ensures index order increases when we later concatenate with the left part.
 * For strict decrease we query ranks strictly below the current:
 *   bestState = fenwick.query(rank - 1)  // consider values < brightness[postIndex]
 *   ldsLength[postIndex] = bestState.maxLength + 1
 *   ldsCount[postIndex] = (bestState.maxLength == 0 ? 1 : bestState.numWays)
 *
 * @param brightness Brightness array brightness[1..numPosts].
 * @param compressionDict Compression dictionary for brightness.
 * @param ldsLength Output vector: ldsLength[postIndex] = strict LDS length starting at postIndex.
 * @param ldsCount Output vector: ldsCount[postIndex] = #ways for that LDS at postIndex (mod MODULUS).
 */
void computeRightStrictDecreasingDp(const std::vector<int>& brightness,
                                    const std::vector<int>& compressionDict,
                                    std::vector<int>& ldsLength,
                                    std::vector<int>& ldsCount) {
    int numPosts = static_cast<int>(brightness.size()) - 1;
    ldsLength.assign(numPosts + 1, 0);
    ldsCount.assign(numPosts + 1, 0);

    FenwickMaxCount fenwick(static_cast<int>(compressionDict.size()));

    for (int postIndex = numPosts; postIndex >= 1; --postIndex) {
        int rank = getRank(compressionDict, brightness[postIndex]);
        DpState bestState = fenwick.query(rank - 1);  // strictly less => strictly decreasing
        int currentLength = bestState.maxLength + 1;
        int currentWays = (bestState.maxLength == 0 ? 1 : bestState.numWays);
        ldsLength[postIndex] = currentLength;
        ldsCount[postIndex] = currentWays;
        fenwick.update(rank, DpState{currentLength, currentWays});
    }
}

/*
 * Combine the left (nondecreasing) and right (strictly decreasing) DP to get the optimal wave length and count.
 *
 * For each pivot postIndex:
 *   waveLength(postIndex) = lndsLength[postIndex] + ldsLength[postIndex] - 1
 * We sum ways where waveLength(postIndex) achieves the global maximum:
 *   totalWays = sum over pivots postIndex of (lndsCount[postIndex] * ldsCount[postIndex]) mod MODULUS.
 *
 * @param lndsLength LNDS lengths ending at postIndex.
 * @param lndsCount LNDS counts at postIndex.
 * @param ldsLength Strict LDS lengths starting at postIndex.
 * @param ldsCount Strict LDS counts at postIndex.
 * @return pair {maxWaveLength K, numberOfMaxWaves W mod MODULUS}.
 */
std::pair<int,int> computeAnswer(const std::vector<int>& lndsLength,
                                 const std::vector<int>& lndsCount,
                                 const std::vector<int>& ldsLength,
                                 const std::vector<int>& ldsCount) {
    int numPosts = static_cast<int>(lndsLength.size()) - 1;

    int maxWaveLength = 0;
    for (int postIndex = 1; postIndex <= numPosts; ++postIndex) {
        maxWaveLength = std::max(maxWaveLength, lndsLength[postIndex] + ldsLength[postIndex] - 1);
    }

    int64_t waysSum = 0;
    for (int postIndex = 1; postIndex <= numPosts; ++postIndex) {
        if (lndsLength[postIndex] + ldsLength[postIndex] - 1 == maxWaveLength) {
            waysSum = (waysSum + 1LL * lndsCount[postIndex] * ldsCount[postIndex]) % MODULUS;
        }
    }
    return {maxWaveLength, static_cast<int>(waysSum)};
}

/*
 * Entry point.
 *
 * Reads input, builds brightness, runs LNDS (left) and strict LDS (right) DP with counting,
 * and prints the optimal wave length K and the number of such waves W (mod MODULUS).
 *
 * @return 0 on success.
 */
int main() {
    std::ios::sync_with_stdio(false);
    std::cin.tie(nullptr);

    int numIntervals, numPosts;
    if (!(std::cin >> numIntervals >> numPosts)) {
        return 0;
    }

    std::vector<std::pair<int,int>> intervals;
    intervals.reserve(numIntervals);
    for (int intervalIndex = 0; intervalIndex < numIntervals; ++intervalIndex) {
        int left, right;
        std::cin >> left >> right;
        intervals.emplace_back(left, right);
    }

    // 1) Build brightness brightness[1..numPosts].
    std::vector<int> brightness = buildBrightness(numPosts, intervals);

    // 2) Coordinate compress brightness values to ranks.
    std::vector<int> compressionDict = makeCompressionDictionary(brightness);

    // 3) Left LNDS and right strict LDS DP (lengths and counts).
    std::vector<int> lndsLength, lndsCount, ldsLength, ldsCount;
    computeLeftNondecreasingDp(brightness, compressionDict, lndsLength, lndsCount);
    computeRightStrictDecreasingDp(brightness, compressionDict, ldsLength, ldsCount);

    // 4) Combine at each pivot to get the answer.
    auto [maxWaveLength, numberOfMaxWaves] = computeAnswer(lndsLength, lndsCount, ldsLength, ldsCount);
    std::cout << maxWaveLength << " " << numberOfMaxWaves << "\n";
    return 0;
}
```

## Code Explanation

### Brightness Construction
- Use a difference array to add $+1$ at each $left$ and $-1$ at each $right+1$. The prefix sums produce brightness $brightness[1], \dots, brightness[numPosts]$ in $O(numIntervals + numPosts)$.

### Coordinate Compression
- Map each brightness value to a rank $1 \dots numRanks$. This provides a compact, ordered domain for the Fenwick tree.

### Left Pass (Non-decreasing)
- For each position $postIndex$ with rank $rank$, query the Fenwick tree over $[1, rank]$ to get the best subsequence ending with a value $\leq brightness[postIndex]$.
- Update $lndsLength[postIndex]$ and $lndsCount[postIndex]$, then merge at $rank$.

### Right Pass (Strictly Decreasing)
- For each position $postIndex$ with rank $rank$, query over $[1, rank-1]$ to enforce strictness $< brightness[postIndex]$ for the right subsequence.
- Update $ldsLength[postIndex]$ and $ldsCount[postIndex]$, then merge at $rank$.

### Combining Results
- The optimal wave length through $postIndex$ is $lndsLength[postIndex] + ldsLength[postIndex] - 1$.
- The total number of maximum waves is the sum over all pivots achieving $K$ of $lndsCount[postIndex] \cdot ldsCount[postIndex]$ modulo $1000000007$.
- The strictness on the right ensures each maximum wave is counted exactly once at its pivot.

## Step-by-Step Example

### Input:
```
2 5
1 3
2 4
```

### Key Intermediate Steps:

**1. Input Parsing:**
- $numIntervals = 2$, $numPosts = 5$
- Intervals: $[(1,3), (2,4)]$

**2. Build Brightness Array:**
- $differenceArray = [0, 1, 1, 0, -1, -1, 0]$
- $brightness = [0, 1, 2, 2, 1, 0]$ (1-indexed)

**3. Coordinate Compression:**
- $compressionDict = [0, 1, 2]$ (sorted unique values)
- Ranks: $brightness[1]=1 \rightarrow rank=2$, $brightness[2]=2 \rightarrow rank=3$, etc.

**4. Left LNDS DP (Nondecreasing):**
- $lndsLength = [0, 1, 2, 3, 2, 1]$
- $lndsCount = [0, 1, 1, 1, 1, 1]$

**5. Right LDS DP (Strictly Decreasing):**
- $ldsLength = [0, 1, 1, 1, 2, 1]$
- $ldsCount = [0, 1, 1, 1, 1, 1]$

**6. Combine Results:**
- For each post: $waveLength = lndsLength + ldsLength - 1$
- Post 1: $1 + 1 - 1 = 1$
- Post 2: $2 + 1 - 1 = 2$
- Post 3: $3 + 1 - 1 = 3$ ← **maximum**
- Post 4: $2 + 2 - 1 = 3$ ← **maximum**
- Post 5: $1 + 1 - 1 = 1$

**7. Count Ways:**
- Posts 3 and 4 achieve maximum length 3
- $totalWays = 1 \times 1 + 1 \times 1 = 2$

### Final Output:
```
3 2
```

## Time and Space Complexity

- **Brightness construction**: $O(numIntervals + numPosts)$ time, $O(numPosts)$ space.
- **Coordinate compression**: $O(numPosts \log numPosts)$ time, $O(numPosts)$ space.
- **Fenwick left and right passes**: $O(numPosts \log numPosts)$ time, $O(numPosts)$ space.
- **Combining results**: $O(numPosts)$ time.

**Overall:**
- **Time complexity**: $O((numIntervals + numPosts) \log numPosts)$.
- **Space complexity**: $O(numPosts)$.

## Conclusion

By transforming the problem into computing, for each index, the longest non-decreasing subsequence to the left and the longest strictly decreasing subsequence to the right (with counts), and using coordinate compression with a Fenwick tree to achieve $O(\log numPosts)$ queries and updates, we obtain an efficient $O((numIntervals + numPosts) \log numPosts)$ solution. The strictness on the right ensures unique pivoting, enabling exact counting of maximum-length waves modulo $1000000007$.